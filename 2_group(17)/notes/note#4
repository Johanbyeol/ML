SVM

두 클래스로부터 최대한 멀리 떨어져 있는 결정 경계를 이용한 분류기

- 선형 SVM 분류
    - 하드 마진 분류 : 모든 훈련 샘플이 도로 밖으로 올바르게 분류되도록 하는 마진분류
    - 소프트 마진 분류 : 도로 폭 넓게, 마진 오류 낮게→이 둘 사이에 적절한 균형을 잡아야함
    
    C낮게 = 도로폭 넓게, 넓은 마진 오류, 낮은 정교함
    
    C높게 = 도로폭 좁게, 적은 마진 오류, 높은 정교함
    
- 비선형 SVM 분류
    
    방식 1 : 선형 SVM에 특성 추가  → 다항 특성 활용, 유사도 특성 활용
    
    - 유사도 특성 활용 : 유사도 특성 + 선형 SVM
        
        유사도 함수 : 각 샘플에 대해 특정 랜드마크(landmark)와의 유사도를 측정하는 함수
        
        ex) 가우시안 방사 기저 함수(RBF, radial basis function)
        
        하이퍼 파라미터 : 랜드마크, 감마(랜드마크에서 멀어질수록 0에 수렴하는 속도 조절)
        
        →랜드마크로부터 조금만 멀어져도 유사도가 매우 빠르게 약해진다.
        
        장점 : 차원이 커지면서 **선형적으로 구분될 가능성이 높아짐**
        
        단점 : 훈련 세트가 매우 클 경우 **아주 많은 특성이 생성됨**
        
    
    방식 2 : SVC + 커널트릭  → 다항식 커널, 가우시안 RBF 커널
    
    - 다항식 커널
        
        다항식 특성 
        
        장점 : 간단, 머신러닝 알고리즘 잘 작동
        
        단점 : 낮은 차수의 다항식은 복잡한 데이터 셋을 잘 표현하지 못함, 높은 차수는 많은 특성을 추가해 모델이 느리게 됨
        
        커널 트릭 - 비선형 문제를 해결하기 위해 데이터를 더 높은 차원으로 변환하여 선형 분류기를 사용할 수 있게 하는 수학적 기법
        
    - 가우시안 RBF 커널
    유사도 특성을 많이 추가하는 것과 같은 비슷한 결과를 얻을 수 있는 커널트릭
        
        하이퍼 파라미터 조절 : gamma
        
        증가 → 종모양 그래프 좁아져 결정 경계가 샘플에 따라 구불구불~
        
        감소 → 종모양 그래프 넓어져 결정 경계가 더 부들부들~
        
        모델의 복잡도 조절하려면 gamma, C 하이퍼파라미터 함께 조정(모델에 과대 적합 시 C 값 감소시켜야함)
        
    
    SVM 회귀(선형) - 제한된 마진 오류 안에서 도로 안에 **가능한 많은 샘플 포함**
    
    도로폭 - 하이퍼 파라미터인 앱실론으로 조절
    
    SVM 회귀(비선형) - 커널 SVM 모델 사용
    
- SVM 이론
    - 결정 함수와 예측
        
        두 평면의 교차점으로 직선이 결정 경계(굵은 실선)
        
        하드 마진 : 마진 오류가 하나도 발생하지 않음
        
        소프트 마진 : 제한적인 마진 오류를 가짐
        
        → 가능한 한 마진을 크게 하는  w와 b를 찾는 것
        
    - 목적 함수
        
        결정 함수의 기울기가 작아질 수록 마진 폭이 커짐(기울기가 ||w||와 비례)
        
        마진을 크게 하기 위해 ||w|| 값 최소화
        
        하드 마진 : 양성 샘플에 대한 결정 함수의 값이 1보다 큼(음성 샘플의 경우 -1보다 작음)
        
        하드 마진 선형 SVM 분류기 → 목적 함수를 최소화 시키는 w와 b를 구해야함
        
        소프트 마진 : 결정 함수의 값이 지정된 값 이상 또는 이하
        
        소프트 마진 선형 SVM 분류기 → 하드 마진과 달리 계산과정에서 C 값과 슬랙변수가 추가
        
    - Quadratic Programming, 쌍대 문제→ 가중치를 최소화하는 최적화 문제
    
    - 커널 SVM
        
        원래 변환된 파이를 계산 해야하나, 변환된 벡터의 점곱이 원래 벡터의 점곱의 제곱과 같다는 특성을 이용해 최적화 문제를 해결
        
        머신러닝에서 커널이란
        
        → 변환 파이를 계산하지 않고 원래 벡터 a와 b에 기반한 점곱을 계산
        
    - 온라인 SVM
        
        온라인 학습 : 새로운 샘플에 대해 점진적으로 학습하는 것
        
        선형 온라인 SVM - loss 하이퍼 파라미터를 hinge로 설정
        
        비선형 온라인 SVM - 대규모인 경우 신경망 알고리즘을 고려해야함(딥 러닝)
