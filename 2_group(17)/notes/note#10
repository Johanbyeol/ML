## **합성곱 신경망을 사용한 컴퓨터 비전**

주요 내용

- CNN의 구성요소
- TF와 케라스르 이용한 CNN의 구현
- 가장 뛰어난 성능의 CNN구조 살표보기
- 활용예 : 객체탐지, 의미분할(시멘틱 분할)

**시각 피질 구조**

국부수용장(local receptive) 모델을 모방 → 합성곱 신경망으로 발전(CNN)

**합성곱 층**

→CNN의 가장 중요한 구성 요소

첫 번째 합성곱 층은 모든 픽셀이 연결되는 것이 아니라 합성곱 층 뉴런의 수용장안에 있는 픽셀에만 연결

두 번째 합성곱 층에 있는 각 뉴런은 첫번째 층의 작은 사각 영역 안에 위치한 뉴런 연결

스트라이드(Stride) : 한 수용장과 다음 수용장 사이의 간격

패딩 : 사방을 특정 값으로 채우는 것(0으로 채우면 제로패딩)

Zero Padding 적용 및 Stride가 1인 경우의 합성곱 연산

**필터(합성곱 터널)**

입력뉴런에 사용될 가중치 역할 → 필터의 가중치를 학습시킴

필터의 모양과 크기 → 국부수용장 모양과 크기 지정

**특성맵(Feature Map)**

- 필터 각각을 사용하여 생성된 출력 값
- 수십, 수백개 필터를 사용
- 각 특성맵 픽셀 → 하나의 뉴런에 해당
- 필터에 포함된 모든 뉴런은 동일한 가중치와 편향 사용
- 필터마다 사용되는 가중치와 편향 값이 다름

**컬러 채널(Color Channel)**

이미지를 대상으로 하는 합성곱 층은 3차원으로 표현이 가능하며 **컬러 이미지면 R, G, B 3개의 채널, 흑백 이미지면 하나의 채널 사용**

특성맵과 컬러채널

뉴런의 출력값 : 각 뉴런의 출력값 = 입력에 대한 가중치의 합 + 편향값

**풀링 층**

- 계산량과 메모리 사용량을 줄이면서 과대적합의 위험도를 줄여주는 역할(차원축소, Feature Map의 사이즈를 줄임)
- 가중치가 없음
- 최대 풀링층(Max Pooling Layer) - BlackBox 기법
    - 2x2 크기의 풀링 커널(Stride = 2) - 4개의 셀 중에 가장 큰 값만 상위 층으로 전달
    - 패딩 없음(padding=”valid”)
    - 파라미터를 획기적으로 줄여서 계산량과 메모리 사용량이 줄고, 많은 정보를 잃지만 잘 작동
- 평균 풀링층(Average Pooling Layer)
    - 폴링커널 구역내의 평균 값 활용
    - 최대 풀링층보다 성능이 떨어짐
                
        최대 풀링층과 평균 풀링층의 예시
        
- 전역 평균 풀링층
    - 각 특성 맵의 평균 계산
    - 현대 신경망 구조에서 종종 활용
- 깊이별 최대/평균 풀링층
    - 지정된 개수의 특성맵을 대상으로 최대/평균을 계산
    

### **CNN 구조**

CNN 구조

과정 : 입력 → 합성곱 → 필터링 →  풀링 → 합성곱 → 필터링 →  풀링 ……. →완전 연결 → 출력

진행할수록 이미지는 점점 작아지지만, 합성곱 층 때문에 일반적으로 점점 더 깊어짐(더 많은 특성맵을 가짐)

합성곱 층에서 사용하는 커널 크기 - 작은 커널을 사용(파라미터와 계산량이 적고 더 나은 성능을 냄)

**CNN 구조의 대표적인 예시**

- LeNet-5
    - **가장 널리 알려진 CNN 구조**
    - 구조 : 입력 → 합성곱 → 평균 풀링 → 합성곱 → 평균 풀링 → 합성곱 → 완전 연결 → 완전 연결(출력)

- AlexNet
    - 합성곱 층위에 풀링 층을 쌓지않고 바로 합성곱 층끼리 쌓음
    - 과대 적합을 줄이기 위해 **두 가지 규제 기법**을 사용
        - 규제 1 : 드롭아웃을 50%로 설정
        - 규제 2 : 데이터 증식 수행 - 수평 뒤집기, 간격 이동, 조명 변경 등을 활용해서 같은 데이터를 여러개로 만듦
    - **정규화 : LRN**(Local Response Normaliztion) - 뉴런의 출력값을 경쟁적으로 만듦 → 각각의 특성맵을 특별하게 만듦 → 다양한 특성 탐색 유도

- GoogNet
    - **인셉션 모듈이라는 서브 네트워크 사용** → 효과적인 파라미터 사용

- VGGNet
    - 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN 구조
    - But, **계층이 16 or 19층으로 심화**
    - 필터는 Only, **3x3 필터만 사용**

- ResNet
    - **잔차 네트워크(Residual Network)** 사용 → 스킵 연결을 사용해 원활한 학습
    - 극도로 깊은 152층의 CNN 사용.

- Xception
    - GoogLeNet과 ResNet 모델의 합성 버전
    - GoogLeNet의 인셉션 모듈 대신 **깊이 별 분리합성곱 층** 사용
        - 공간별 패턴인식 : 형태 인식
        - 깊이별 패턴인식 : 채널 사이의 패턴 인식

- SENet
    - 인셉션 모듈과 잔차유닛에 **SE block을 추가**하여 더 나은 성능 발휘

- MobileNet
    - 스마트폰 및 기타 모바일 장치와 같이 리소스가 제한된 환경에서 효율적인 계산을 위해 설계된 **경량 심층신경망**
    - Depthwise Separable Convolution
