1) 기계 학습에서 학습이란 무엇인지를 정리하시오(2점). 
( 가중치, 손실함수가 무엇인지를 정리하고, 데이터, 가중치, 손실함수를 이용하여 학습이 무엇인지를 정리함.) 

가중치: 각 입력 신호가 결과 출력에 미치는 중요도를 조절하는 매개변수
입력데이터와 모델의 출력 사이의 관계를 정의하는 매개변수이다. 가중치는 특정 입력변수의 중요성을 나타내고, 모델의 입력 데이터를 분석하여
예측을 수행할 때 각 입력 변수의 영향력을 조절한다.

주로 선형모델 및 신경망 모델에 사용된다. 선형 모델에서는 각 입력 피쳐에 대한 가중치가 선형 결합을 통해 예측을 생성한다. 신경망 모델에서는 
각 뉴런과 연결된 가중치가 입력과 활성화 함수를 통과한 후 출력을 결정한다.

손실함수: 모델을 학습할 때 정답값과 예측값의 오차를 계산해주는 함수
기계 학습 모델의 성능을 평가하고 모델의 학습을 조절하기 위한 중요한 지표이다. 손실 함수는 모델의 예측과 실제 정답(또는 목표) 간의 차이, 
즉 오차를 측정하는 함수로서 사용된다. 손실 함수의 목표는 이 오차를 최소화하거나 최적화하여 모델이 주어진 작업을 잘 수행하도록 돕는 것이다.
-> 손실 함수의 선택은 기계 학습 작업의 특성에 따라 다양하게 결정된다.

학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것
모델이 학습할 수 있도록 해주는 지표로 손실 함수가 있는데, 이 손실 함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표이다.

2) 확률적 경사 하강법의 소스 코드를 분석하시오(2점). (Page 173, 4장 모델 훈련, 첨부 파일 참조)

확률적 경사 하강법 코드
----------------------------------------------
#전체 학습 주기(epochs)수를 나타내는 것으로 50번의 에포크동안 모델을 학습
n_epochs = 50
#t0와 t1은 학습 스케줄을 결정하는 매개 변수로 학습률을 조절하는데 사용
t0, t1 = 5, 50

#t0 / (t + t1)의 형태로 학습률을 계산
def learning_schedule(t):
  return t0 / (t + t1)

#무작위로 설정된 모델의 가중치
theta = np.random.randn(2, 1)

#주요 루프로 전체 학습 주기(epochs=50)동안 반복
for epoch in range(n_epochs):
  #내부 루프로 학습 데이터 포인트의 인덱스에 대한 루프
  for i in range(m):
    #무작위로 데이터 포인터를 선택하는것으로 가중치를 업데이트
    random_index = np.random.randint(m)
    #xi와 yi는 선택된 무작위 데이터 포인트의 입력과 레이블
    xi = X_b[random_index:random_index + 1]
    yi = y[random_index:random_index + 1]
    #기울기 계산으로 손실함수의 기울기
    gradients = 2 * xi.T.dot(xi.dot(theta) - yi)
    #현재 학습률을 학습 스케줄 함수로 계산
    eta = learning_schedule(epoch * m + i)
    #가중치 업데이트로 손실함수를 최소화하기 위해 가중치 조절
    theta = theta - eta * gradients
----------------------------------------------

